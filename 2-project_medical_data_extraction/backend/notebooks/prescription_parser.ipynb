{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60c71ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdf2image import convert_from_path           # The convert_from_path function imported from the pdf2image library serves the purpose of converting PDF files into a list of PIL (Python Imaging Library) image objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bb0252d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = convert_from_path(r\"docs\\prescription\\pre_1.pdf\", poppler_path= r\"C:\\poppler-24.02.0\\Library\\bin\")     # The poppler_path parameter enables specifying the path to the Poppler utility, essential for tools like pdf2image to efficiently interpret PDF contents, simplifying PDF manipulation in your programs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c70b8c36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<PIL.PpmImagePlugin.PpmImageFile image mode=RGB size=1700x2200>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8c629eec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3d21199d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f69a75ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Currently i got only one image as there was only one page in the pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72d3b984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this command will show the image\n",
    "pages[0].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac3a084d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7c3f534d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dr John Smith, M.D\n",
      "2 Non-Important Street,\n",
      "New York, Phone (000)-111-2222\n",
      "\n",
      "Name: Maria Sharapova Date: 5/11/2022\n",
      "\n",
      "Address: 9 tennis court, new Russia, DC\n",
      "\n",
      "â€”moemenmannenneneneunmnnnnennieesisiyoinnitniahadaaanniihsnseneneneeeernnttnnneenrenen:\n",
      "\n",
      "Prednisone 20 mg\n",
      "Lialda 2.4 gram\n",
      "\n",
      "3 days,\n",
      "\n",
      "or 1 month\n"
     ]
    }
   ],
   "source": [
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"      # This line of code ensures that pytesseract knows where to find the Tesseract OCR tool{a.k.a.  google tesseract engine} so it can be used for text recognition tasks.\n",
    "text = pytesseract.image_to_string(pages[0], lang = 'eng')                                          # `image_to_string()` function is used to convert an image into text. can also specify language, if the image has text in diffrent language then can specify that\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37823e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we got the text from the image, but note it is not perfect, we were not able to get the text part that was in shadow.\n",
    "# this means that i cannot apply this tesseract directly to the image because the image is not perfect , i have to apply some image preprocessing before using the tesseract to extract text from the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e726bf71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "def preprocess_image(img):\n",
    "    gray = cv2.cvtColor(np.array(img), cv2.COLOR_BGR2GRAY)      # `np.array` will convert the image into array form, and our image is a scanned image,it could be in coloured form,so first i have to convert that into greyscale form{black and white form}, which simplifies the image for further processing. For that we use `cv2.COLOR_BGR2GRAY`\n",
    "    resized = cv2.resize(gray, None, fx=1.5, fy=1.5, interpolation=cv2.INTER_LINEAR)  # this involves changing the dimension of the image. Here, image enlarged by 1.5 in both horizontal and vertical directions{this 1.5 value is chosen after trial and error}\n",
    "    processed_image = cv2.adaptiveThreshold(\n",
    "        resized,\n",
    "        255,\n",
    "        cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
    "        cv2.THRESH_BINARY, \n",
    "        61,\n",
    "        11\n",
    "    )\n",
    "    return processed_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e2cbf8",
   "metadata": {},
   "source": [
    "* `fx` stands for \"factor along the x-axis\" and `fy` stands for \"factor along y-axis\"\n",
    "* The `None` value passed as the second argument to `cv2.resize` indicates that the output size of the resized image is not explicitly defined. When `None` is provided, the function automatically calculates the dimensions of the output image based on the scaling factors provided in `fx` and `fy`.\n",
    "  If we specify output size then no need to specify `fx` and `fy` values.\n",
    "* `interpolation`: thsi parameter specifies teh method used to interpolate between pixel values when resizing. Here, \"cv2.INTER_LINEAR\" means linear interpolation is used. Linear interpolation calculates new pixel values based on weighted averages of surrounding pixels.\n",
    "\n",
    "**Overall, the resizing step increases the size of the grayscale image to enhance features or details, making them easier to detect in further processing steps.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e5f881dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = preprocess_image(pages[0])\n",
    "Image.fromarray(img).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b177983c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dr John Smith, M.D\n",
      "2 Non-Important Street,\n",
      "New York, Phone (000)-111-2222\n",
      "\n",
      "Name: Marta Sharapova Date: 5/11/2022\n",
      "\n",
      "Address: 9 tennis court, new Russia, DC\n",
      "\n",
      "K\n",
      "\n",
      "Prednisone 20 mg\n",
      "Lialda 2.4 gram\n",
      "\n",
      "Directions:\n",
      "\n",
      "Prednisone, Taper 5 mig every 3 days,\n",
      "Finish in 2.5 weeks a\n",
      "Lialda - take 2 pill everyday for 1 month\n",
      "\n",
      "Refill: 2 times\n"
     ]
    }
   ],
   "source": [
    "# now will apply the teseract to extract text from the post processed image\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
    "text = pytesseract.image_to_string(img, lang = 'eng')\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8441de75",
   "metadata": {},
   "source": [
    "**Note**: after post-processinh we are able to extract all the texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37c8f9d",
   "metadata": {},
   "source": [
    "Now we apply the same program on the second pdf from the \"Docs\" folder.\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "442d5157",
   "metadata": {},
   "source": [
    "pages = convert_from_path(r\"docs\\prescription\\pre_2.pdf\", poppler_path= r\"C:\\poppler-24.02.0\\Library\\bin\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f24e425d",
   "metadata": {},
   "source": [
    "len(pages)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "974f213a",
   "metadata": {},
   "source": [
    "pages[0].show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "12d61878",
   "metadata": {},
   "source": [
    "img = preprocess_image(pages[0])\n",
    "Image.fromarray(img).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ecd36e3",
   "metadata": {},
   "source": [
    "**note** after the processing we got the image a little tilted, due to which when we extrcat the text we will find error"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b0cb29cf",
   "metadata": {},
   "source": [
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
    "text = pytesseract.image_to_string(img, lang = 'eng')\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da20502",
   "metadata": {},
   "source": [
    "Clearly can see in place of \"S\" it has extracted \">\" etc. This shows that project will **not give 100 percent accurcay**. With this automation, we might have to corrcet some of the errors manually. So, **our project is a combination of automation and human effort**.\n",
    "But still it mostly working fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98121e2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
